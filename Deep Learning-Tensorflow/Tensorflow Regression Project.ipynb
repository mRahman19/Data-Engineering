{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Regression Project\n",
    "\n",
    "California Housing Data\n",
    "\n",
    "This data set contains information about all the block groups in California from the 1990 Census.\n",
    "\n",
    "The task is to aproximate the median house value of each block from the values of the rest of the variables. \n",
    "\n",
    "Dataset -  http://www.liaad.up.pt/~ltorgo/Regression/DataSets.html.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Features:\n",
    " \n",
    "* housingMedianAge: continuous. \n",
    "* totalRooms: continuous. \n",
    "* totalBedrooms: continuous. \n",
    "* population: continuous. \n",
    "* households: continuous. \n",
    "* medianIncome: continuous. \n",
    "* medianHouseValue: continuous. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv('cal_housing_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "0              41.0       880.0          129.0       322.0       126.0   \n",
       "1              21.0      7099.0         1106.0      2401.0      1138.0   \n",
       "2              52.0      1467.0          190.0       496.0       177.0   \n",
       "3              52.0      1274.0          235.0       558.0       219.0   \n",
       "4              52.0      1627.0          280.0       565.0       259.0   \n",
       "\n",
       "   medianIncome  medianHouseValue  \n",
       "0        8.3252          452600.0  \n",
       "1        8.3014          358500.0  \n",
       "2        7.2574          352100.0  \n",
       "3        5.6431          341300.0  \n",
       "4        3.8462          342200.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>housingMedianAge</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>52.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalRooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1447.7500</td>\n",
       "      <td>2127.0000</td>\n",
       "      <td>3148.00000</td>\n",
       "      <td>39320.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalBedrooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>537.898014</td>\n",
       "      <td>421.247906</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>295.0000</td>\n",
       "      <td>435.0000</td>\n",
       "      <td>647.00000</td>\n",
       "      <td>6445.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>787.0000</td>\n",
       "      <td>1166.0000</td>\n",
       "      <td>1725.00000</td>\n",
       "      <td>35682.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>280.0000</td>\n",
       "      <td>409.0000</td>\n",
       "      <td>605.00000</td>\n",
       "      <td>6082.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianIncome</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>0.4999</td>\n",
       "      <td>2.5634</td>\n",
       "      <td>3.5348</td>\n",
       "      <td>4.74325</td>\n",
       "      <td>15.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianHouseValue</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>206855.816909</td>\n",
       "      <td>115395.615874</td>\n",
       "      <td>14999.0000</td>\n",
       "      <td>119600.0000</td>\n",
       "      <td>179700.0000</td>\n",
       "      <td>264725.00000</td>\n",
       "      <td>500001.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count           mean            std         min  \\\n",
       "housingMedianAge  20640.0      28.639486      12.585558      1.0000   \n",
       "totalRooms        20640.0    2635.763081    2181.615252      2.0000   \n",
       "totalBedrooms     20640.0     537.898014     421.247906      1.0000   \n",
       "population        20640.0    1425.476744    1132.462122      3.0000   \n",
       "households        20640.0     499.539680     382.329753      1.0000   \n",
       "medianIncome      20640.0       3.870671       1.899822      0.4999   \n",
       "medianHouseValue  20640.0  206855.816909  115395.615874  14999.0000   \n",
       "\n",
       "                          25%          50%           75%          max  \n",
       "housingMedianAge      18.0000      29.0000      37.00000      52.0000  \n",
       "totalRooms          1447.7500    2127.0000    3148.00000   39320.0000  \n",
       "totalBedrooms        295.0000     435.0000     647.00000    6445.0000  \n",
       "population           787.0000    1166.0000    1725.00000   35682.0000  \n",
       "households           280.0000     409.0000     605.00000    6082.0000  \n",
       "medianIncome           2.5634       3.5348       4.74325      15.0001  \n",
       "medianHouseValue  119600.0000  179700.0000  264725.00000  500001.0000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.describe().transpose()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_data = housing.drop(['medianHouseValue'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = housing['medianHouseValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_data,y_val,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Feature Data\n",
    "\n",
    "** Use sklearn preprocessing to create a MinMaxScaler for the feature data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(data=scaler.transform(X_train),columns = X_train.columns,index=X_train.index)\n",
    "X_test = pd.DataFrame(data=scaler.transform(X_test),columns = X_test.columns,index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Columns\n",
    "\n",
    "** Create the necessary tf.feature_column objects for the estimator **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['housingMedianAge', 'totalRooms', 'totalBedrooms', 'population',\n",
       "       'households', 'medianIncome', 'medianHouseValue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rahman\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create continuous feature_columns for the continuous values using numeric_column **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column('housingMedianAge')\n",
    "rooms = tf.feature_column.numeric_column('totalRooms')\n",
    "bedrooms = tf.feature_column.numeric_column('totalBedrooms')\n",
    "pop = tf.feature_column.numeric_column('population')\n",
    "households = tf.feature_column.numeric_column('households')\n",
    "income = tf.feature_column.numeric_column('medianIncome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [ age,rooms,bedrooms,pop,households,income]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the input function for the estimator object. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train ,batch_size=10,num_epochs=1000,\n",
    "                                            shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the estimator model, Use a DNNRegressor **\n",
    "** Create 3 layer and 6 neoron for each layer **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Rahman\\AppData\\Local\\Temp\\tmp7viio4i1\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Rahman\\\\AppData\\\\Local\\\\Temp\\\\tmp7viio4i1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000021E302779E8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNRegressor(hidden_units=[6,6,6],feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Train the model for 10000 steps. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Rahman\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\Rahman\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From C:\\Users\\Rahman\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\Rahman\\AppData\\Local\\Temp\\tmp7viio4i1\\model.ckpt.\n",
      "INFO:tensorflow:loss = 585524640000.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 275.963\n",
      "INFO:tensorflow:loss = 659495300000.0, step = 101 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.932\n",
      "INFO:tensorflow:loss = 695286240000.0, step = 201 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.761\n",
      "INFO:tensorflow:loss = 563958800000.0, step = 301 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.471\n",
      "INFO:tensorflow:loss = 415198180000.0, step = 401 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.429\n",
      "INFO:tensorflow:loss = 480888600000.0, step = 501 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.958\n",
      "INFO:tensorflow:loss = 312028900000.0, step = 601 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.197\n",
      "INFO:tensorflow:loss = 548203130000.0, step = 701 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.313\n",
      "INFO:tensorflow:loss = 450585100000.0, step = 801 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.757\n",
      "INFO:tensorflow:loss = 178124100000.0, step = 901 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.823\n",
      "INFO:tensorflow:loss = 520348760000.0, step = 1001 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.606\n",
      "INFO:tensorflow:loss = 561631700000.0, step = 1101 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.652\n",
      "INFO:tensorflow:loss = 370669030000.0, step = 1201 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.168\n",
      "INFO:tensorflow:loss = 332002850000.0, step = 1301 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.094\n",
      "INFO:tensorflow:loss = 156633280000.0, step = 1401 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.907\n",
      "INFO:tensorflow:loss = 176350270000.0, step = 1501 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.432\n",
      "INFO:tensorflow:loss = 288054740000.0, step = 1601 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.685\n",
      "INFO:tensorflow:loss = 290541830000.0, step = 1701 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.149\n",
      "INFO:tensorflow:loss = 636790500000.0, step = 1801 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.425\n",
      "INFO:tensorflow:loss = 326042450000.0, step = 1901 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.165\n",
      "INFO:tensorflow:loss = 204387140000.0, step = 2001 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.682\n",
      "INFO:tensorflow:loss = 374919660000.0, step = 2101 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.606\n",
      "INFO:tensorflow:loss = 235729670000.0, step = 2201 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.119\n",
      "INFO:tensorflow:loss = 236013290000.0, step = 2301 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.706\n",
      "INFO:tensorflow:loss = 229827410000.0, step = 2401 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.407\n",
      "INFO:tensorflow:loss = 176497360000.0, step = 2501 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.702\n",
      "INFO:tensorflow:loss = 209448240000.0, step = 2601 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.045\n",
      "INFO:tensorflow:loss = 183439130000.0, step = 2701 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.68\n",
      "INFO:tensorflow:loss = 195652760000.0, step = 2801 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.254\n",
      "INFO:tensorflow:loss = 376180670000.0, step = 2901 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.368\n",
      "INFO:tensorflow:loss = 46528016000.0, step = 3001 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.921\n",
      "INFO:tensorflow:loss = 34173522000.0, step = 3101 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.394\n",
      "INFO:tensorflow:loss = 127988770000.0, step = 3201 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.655\n",
      "INFO:tensorflow:loss = 106840720000.0, step = 3301 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.675\n",
      "INFO:tensorflow:loss = 150849290000.0, step = 3401 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.126\n",
      "INFO:tensorflow:loss = 49955914000.0, step = 3501 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.004\n",
      "INFO:tensorflow:loss = 128233960000.0, step = 3601 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.427\n",
      "INFO:tensorflow:loss = 118087190000.0, step = 3701 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.929\n",
      "INFO:tensorflow:loss = 174382070000.0, step = 3801 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.666\n",
      "INFO:tensorflow:loss = 71460585000.0, step = 3901 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.144\n",
      "INFO:tensorflow:loss = 103371980000.0, step = 4001 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.65\n",
      "INFO:tensorflow:loss = 149441330000.0, step = 4101 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.888\n",
      "INFO:tensorflow:loss = 75638110000.0, step = 4201 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.549\n",
      "INFO:tensorflow:loss = 44411003000.0, step = 4301 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.789\n",
      "INFO:tensorflow:loss = 112272120000.0, step = 4401 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.201\n",
      "INFO:tensorflow:loss = 122676910000.0, step = 4501 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.514\n",
      "INFO:tensorflow:loss = 149607330000.0, step = 4601 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.719\n",
      "INFO:tensorflow:loss = 97634580000.0, step = 4701 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.956\n",
      "INFO:tensorflow:loss = 187486030000.0, step = 4801 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.45\n",
      "INFO:tensorflow:loss = 90012340000.0, step = 4901 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.631\n",
      "INFO:tensorflow:loss = 171556960000.0, step = 5001 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.128\n",
      "INFO:tensorflow:loss = 67580320000.0, step = 5101 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.65\n",
      "INFO:tensorflow:loss = 99952420000.0, step = 5201 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.501\n",
      "INFO:tensorflow:loss = 75859870000.0, step = 5301 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.572\n",
      "INFO:tensorflow:loss = 121729690000.0, step = 5401 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.929\n",
      "INFO:tensorflow:loss = 95004025000.0, step = 5501 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.851\n",
      "INFO:tensorflow:loss = 89895770000.0, step = 5601 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.797\n",
      "INFO:tensorflow:loss = 174498610000.0, step = 5701 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.548\n",
      "INFO:tensorflow:loss = 98485895000.0, step = 5801 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.976\n",
      "INFO:tensorflow:loss = 166230360000.0, step = 5901 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.428\n",
      "INFO:tensorflow:loss = 44923265000.0, step = 6001 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.75\n",
      "INFO:tensorflow:loss = 182939160000.0, step = 6101 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.619\n",
      "INFO:tensorflow:loss = 132685360000.0, step = 6201 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.679\n",
      "INFO:tensorflow:loss = 182212590000.0, step = 6301 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.231\n",
      "INFO:tensorflow:loss = 184353770000.0, step = 6401 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.565\n",
      "INFO:tensorflow:loss = 70506996000.0, step = 6501 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.219\n",
      "INFO:tensorflow:loss = 83277160000.0, step = 6601 (0.322 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 295.395\n",
      "INFO:tensorflow:loss = 100004930000.0, step = 6701 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.249\n",
      "INFO:tensorflow:loss = 129058800000.0, step = 6801 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.87\n",
      "INFO:tensorflow:loss = 51665120000.0, step = 6901 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.532\n",
      "INFO:tensorflow:loss = 111959880000.0, step = 7001 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.424\n",
      "INFO:tensorflow:loss = 142735540000.0, step = 7101 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.11\n",
      "INFO:tensorflow:loss = 218421600000.0, step = 7201 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.713\n",
      "INFO:tensorflow:loss = 66542227000.0, step = 7301 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.882\n",
      "INFO:tensorflow:loss = 213172830000.0, step = 7401 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.187\n",
      "INFO:tensorflow:loss = 104784680000.0, step = 7501 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.974\n",
      "INFO:tensorflow:loss = 208408790000.0, step = 7601 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.186\n",
      "INFO:tensorflow:loss = 66433850000.0, step = 7701 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.673\n",
      "INFO:tensorflow:loss = 125934220000.0, step = 7801 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.443\n",
      "INFO:tensorflow:loss = 92179350000.0, step = 7901 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.364\n",
      "INFO:tensorflow:loss = 76343800000.0, step = 8001 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.323\n",
      "INFO:tensorflow:loss = 35993215000.0, step = 8101 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.11\n",
      "INFO:tensorflow:loss = 282768700000.0, step = 8201 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.196\n",
      "INFO:tensorflow:loss = 84667890000.0, step = 8301 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.225\n",
      "INFO:tensorflow:loss = 104386480000.0, step = 8401 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.779\n",
      "INFO:tensorflow:loss = 34640654000.0, step = 8501 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.576\n",
      "INFO:tensorflow:loss = 105149320000.0, step = 8601 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.571\n",
      "INFO:tensorflow:loss = 111797850000.0, step = 8701 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.046\n",
      "INFO:tensorflow:loss = 103772420000.0, step = 8801 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.959\n",
      "INFO:tensorflow:loss = 50775760000.0, step = 8901 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.211\n",
      "INFO:tensorflow:loss = 116370110000.0, step = 9001 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.277\n",
      "INFO:tensorflow:loss = 62112526000.0, step = 9101 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.237\n",
      "INFO:tensorflow:loss = 124788335000.0, step = 9201 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.505\n",
      "INFO:tensorflow:loss = 84139155000.0, step = 9301 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.216\n",
      "INFO:tensorflow:loss = 43186760000.0, step = 9401 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.043\n",
      "INFO:tensorflow:loss = 41695433000.0, step = 9501 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.135\n",
      "INFO:tensorflow:loss = 84957810000.0, step = 9601 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.906\n",
      "INFO:tensorflow:loss = 119799865000.0, step = 9701 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.296\n",
      "INFO:tensorflow:loss = 105669280000.0, step = 9801 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.88\n",
      "INFO:tensorflow:loss = 137813520000.0, step = 9901 (0.291 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into C:\\Users\\Rahman\\AppData\\Local\\Temp\\tmp7viio4i1\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 97599310000.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x21e30277320>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func,steps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create prediction input function then use .predict method off estimator model to create a list or predictions on test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "      x=X_test,\n",
    "      batch_size=10,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gen = model.predict(predict_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Rahman\\AppData\\Local\\Temp\\tmp7viio4i1\\model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = list(pred_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Calculate the RMSE. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([228244.97], dtype=float32),\n",
       " array([271712.47], dtype=float32),\n",
       " array([223316.34], dtype=float32),\n",
       " array([180512.23], dtype=float32),\n",
       " array([246377.16], dtype=float32),\n",
       " array([202837.62], dtype=float32),\n",
       " array([232586.06], dtype=float32),\n",
       " array([208021.25], dtype=float32),\n",
       " array([208304.3], dtype=float32),\n",
       " array([167561.], dtype=float32)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 104999.69308056065\n"
     ]
    }
   ],
   "source": [
    "print('MSE : {}'.format(mean_squared_error(y_test,final_preds)**0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
