{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tensorflow Classification Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be working with some California Census Data, we'll be trying to use various features of an individual to predict what class of income they belogn in (>50k or <=50k). \n",
    "\n",
    "Here is some information about the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Column Name</th>\n",
    "<th>Type</th>\n",
    "<th>Description</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>age</td>\n",
    "<td>Continuous</td>\n",
    "<td>The age of the individual</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>workclass</td>\n",
    "<td>Categorical</td>\n",
    "<td>The type of employer the  individual has (government,  military, private, etc.).</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>fnlwgt</td>\n",
    "<td>Continuous</td>\n",
    "<td>The number of people the census  takers believe that observation  represents (sample weight). This  variable will not be used.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education</td>\n",
    "<td>Categorical</td>\n",
    "<td>The highest level of education  achieved for that individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education_num</td>\n",
    "<td>Continuous</td>\n",
    "<td>The highest level of education in  numerical form.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>marital_status</td>\n",
    "<td>Categorical</td>\n",
    "<td>Marital status of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>occupation</td>\n",
    "<td>Categorical</td>\n",
    "<td>The occupation of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>relationship</td>\n",
    "<td>Categorical</td>\n",
    "<td>Wife, Own-child, Husband,  Not-in-family, Other-relative,  Unmarried.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>race</td>\n",
    "<td>Categorical</td>\n",
    "<td>White, Asian-Pac-Islander,  Amer-Indian-Eskimo, Other, Black.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>gender</td>\n",
    "<td>Categorical</td>\n",
    "<td>Female, Male.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_gain</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital gains recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_loss</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital Losses recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>hours_per_week</td>\n",
    "<td>Continuous</td>\n",
    "<td>Hours worked per week.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>native_country</td>\n",
    "<td>Categorical</td>\n",
    "<td>Country of origin of the  individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>income</td>\n",
    "<td>Categorical</td>\n",
    "<td>\"&gt;50K\" or \"&lt;=50K\", meaning  whether the person makes more  than \\$50,000 annually.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read in the census_data.csv data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = pd.read_csv(\"census_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country income_bracket  \n",
       "0             0              40   United-States          <=50K  \n",
       "1             0              13   United-States          <=50K  \n",
       "2             0              40   United-States          <=50K  \n",
       "3             0              40   United-States          <=50K  \n",
       "4             0              40            Cuba          <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** TensorFlow won't be able to understand strings as labels, we need to use pandas .apply() method to apply a custom function that converts them to 0s and 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census['income_bracket'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_fix(label):\n",
    "    if label==' <=50K':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "census['income_bracket'] = census['income_bracket'].apply(label_fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a Train Test Split on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = census.drop('income_bracket',axis=1)\n",
    "y_labels = census['income_bracket']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data,y_labels,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Columns for tf.esitmator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'education', 'education_num', 'marital_status',\n",
       "       'occupation', 'relationship', 'race', 'gender', 'capital_gain',\n",
       "       'capital_loss', 'hours_per_week', 'native_country', 'income_bracket'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import Tensorflow **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rahman\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Create the tf.feature_columns for the categorical values. Use vocabulary lists or just use hash buckets. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = tf.feature_column.categorical_column_with_vocabulary_list(\"gender\", [\"Female\", \"Male\"])\n",
    "occupation = tf.feature_column.categorical_column_with_hash_bucket(\"occupation\", hash_bucket_size=1000)\n",
    "marital_status = tf.feature_column.categorical_column_with_hash_bucket(\"marital_status\", hash_bucket_size=1000)\n",
    "relationship = tf.feature_column.categorical_column_with_hash_bucket(\"relationship\", hash_bucket_size=1000)\n",
    "education = tf.feature_column.categorical_column_with_hash_bucket(\"education\", hash_bucket_size=1000)\n",
    "workclass = tf.feature_column.categorical_column_with_hash_bucket(\"workclass\", hash_bucket_size=1000)\n",
    "native_country = tf.feature_column.categorical_column_with_hash_bucket(\"native_country\", hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Embeded categorical column  ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = tf.feature_column.embedding_column(gender, dimension=2)\n",
    "occupation = tf.feature_column.embedding_column(occupation, dimension=1000)\n",
    "marital_status = tf.feature_column.embedding_column(marital_status, dimension=1000)\n",
    "relationship = tf.feature_column.embedding_column(relationship, dimension=1000)\n",
    "education = tf.feature_column.embedding_column(education, dimension=1000)\n",
    "workclass = tf.feature_column.embedding_column(workclass, dimension=1000)\n",
    "native_country = tf.feature_column.embedding_column(native_country, dimension=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create continuous feature_columns for the continuous values using numeric_column **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column(\"age\")\n",
    "education_num = tf.feature_column.numeric_column(\"education_num\")\n",
    "capital_gain = tf.feature_column.numeric_column(\"capital_gain\")\n",
    "capital_loss = tf.feature_column.numeric_column(\"capital_loss\")\n",
    "hours_per_week = tf.feature_column.numeric_column(\"hours_per_week\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Put all these variables into a single list **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [gender,occupation,marital_status,relationship,education,workclass,native_country,\n",
    "            age,education_num,capital_gain,capital_loss,hours_per_week]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Input Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func=tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train,batch_size=100,num_epochs=None,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create model with tf.estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Rahman\\AppData\\Local\\Temp\\tmpvfsfue7f\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Rahman\\\\AppData\\\\Local\\\\Temp\\\\tmpvfsfue7f', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000257AB770518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNClassifier(hidden_units=[6,6,6], feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train your model on the data, for 10000 steps. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Rahman\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\Rahman\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From C:\\Users\\Rahman\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\Rahman\\AppData\\Local\\Temp\\tmpvfsfue7f\\model.ckpt.\n",
      "INFO:tensorflow:loss = 76.41508, step = 1\n",
      "INFO:tensorflow:global_step/sec: 26.2968\n",
      "INFO:tensorflow:loss = 45.091267, step = 101 (3.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.1116\n",
      "INFO:tensorflow:loss = 30.906637, step = 201 (3.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.4635\n",
      "INFO:tensorflow:loss = 46.811626, step = 301 (2.886 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.5114\n",
      "INFO:tensorflow:loss = 36.301617, step = 401 (2.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.5683\n",
      "INFO:tensorflow:loss = 44.403107, step = 501 (2.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.3054\n",
      "INFO:tensorflow:loss = 34.61058, step = 601 (2.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.6294\n",
      "INFO:tensorflow:loss = 39.87319, step = 701 (2.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.4903\n",
      "INFO:tensorflow:loss = 35.59219, step = 801 (2.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.104\n",
      "INFO:tensorflow:loss = 33.973953, step = 901 (2.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.9168\n",
      "INFO:tensorflow:loss = 43.134003, step = 1001 (2.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.3509\n",
      "INFO:tensorflow:loss = 31.00547, step = 1101 (2.927 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.8266\n",
      "INFO:tensorflow:loss = 39.618603, step = 1201 (2.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.9962\n",
      "INFO:tensorflow:loss = 36.890682, step = 1301 (2.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.0404\n",
      "INFO:tensorflow:loss = 29.70907, step = 1401 (2.838 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.5367\n",
      "INFO:tensorflow:loss = 40.465275, step = 1501 (2.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.899\n",
      "INFO:tensorflow:loss = 39.042633, step = 1601 (2.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.9894\n",
      "INFO:tensorflow:loss = 29.139296, step = 1701 (2.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.0411\n",
      "INFO:tensorflow:loss = 29.067078, step = 1801 (2.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.9763\n",
      "INFO:tensorflow:loss = 32.301006, step = 1901 (2.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.8845\n",
      "INFO:tensorflow:loss = 36.13346, step = 2001 (3.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.4787\n",
      "INFO:tensorflow:loss = 43.725246, step = 2101 (3.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.8648\n",
      "INFO:tensorflow:loss = 37.321762, step = 2201 (2.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.8986\n",
      "INFO:tensorflow:loss = 32.594578, step = 2301 (2.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.4908\n",
      "INFO:tensorflow:loss = 44.558918, step = 2401 (2.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.9923\n",
      "INFO:tensorflow:loss = 27.687292, step = 2501 (2.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.1471\n",
      "INFO:tensorflow:loss = 33.946625, step = 2601 (3.033 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.5796\n",
      "INFO:tensorflow:loss = 36.922184, step = 2701 (2.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.008\n",
      "INFO:tensorflow:loss = 35.20617, step = 2801 (2.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.5616\n",
      "INFO:tensorflow:loss = 52.720898, step = 2901 (2.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.936\n",
      "INFO:tensorflow:loss = 34.963703, step = 3001 (2.951 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.1541\n",
      "INFO:tensorflow:loss = 35.938557, step = 3101 (2.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.0111\n",
      "INFO:tensorflow:loss = 31.297718, step = 3201 (2.956 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.263\n",
      "INFO:tensorflow:loss = 26.254826, step = 3301 (2.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.8209\n",
      "INFO:tensorflow:loss = 33.84511, step = 3401 (2.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.5726\n",
      "INFO:tensorflow:loss = 34.287422, step = 3501 (2.892 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.5489\n",
      "INFO:tensorflow:loss = 31.288671, step = 3601 (2.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.4888\n",
      "INFO:tensorflow:loss = 25.650333, step = 3701 (2.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.6477\n",
      "INFO:tensorflow:loss = 39.220547, step = 3801 (2.886 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.2364\n",
      "INFO:tensorflow:loss = 27.777216, step = 3901 (2.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.5454\n",
      "INFO:tensorflow:loss = 42.96773, step = 4001 (2.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.4125\n",
      "INFO:tensorflow:loss = 32.93018, step = 4101 (2.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.4458\n",
      "INFO:tensorflow:loss = 22.073034, step = 4201 (2.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.547\n",
      "INFO:tensorflow:loss = 33.14781, step = 4301 (3.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.4431\n",
      "INFO:tensorflow:loss = 28.719389, step = 4401 (3.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.8063\n",
      "INFO:tensorflow:loss = 35.15199, step = 4501 (2.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.4005\n",
      "INFO:tensorflow:loss = 35.80263, step = 4601 (2.908 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.8384\n",
      "INFO:tensorflow:loss = 30.084513, step = 4701 (2.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.6258\n",
      "INFO:tensorflow:loss = 31.473585, step = 4801 (2.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.0365\n",
      "INFO:tensorflow:loss = 39.68215, step = 4901 (2.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.7174\n",
      "INFO:tensorflow:loss = 38.67986, step = 5001 (2.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.5101\n",
      "INFO:tensorflow:loss = 33.285847, step = 5101 (2.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.6279\n",
      "INFO:tensorflow:loss = 36.2678, step = 5201 (2.888 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.0439\n",
      "INFO:tensorflow:loss = 31.13717, step = 5301 (2.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.6183\n",
      "INFO:tensorflow:loss = 36.297543, step = 5401 (2.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.2047\n",
      "INFO:tensorflow:loss = 23.62814, step = 5501 (2.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.4372\n",
      "INFO:tensorflow:loss = 42.514538, step = 5601 (2.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.9439\n",
      "INFO:tensorflow:loss = 35.53446, step = 5701 (2.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.7318\n",
      "INFO:tensorflow:loss = 29.002005, step = 5801 (2.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.0798\n",
      "INFO:tensorflow:loss = 34.656086, step = 5901 (2.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.9418\n",
      "INFO:tensorflow:loss = 35.974033, step = 6001 (2.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.4013\n",
      "INFO:tensorflow:loss = 32.58273, step = 6101 (2.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.4971\n",
      "INFO:tensorflow:loss = 41.191956, step = 6201 (2.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.7631\n",
      "INFO:tensorflow:loss = 36.597855, step = 6301 (2.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.8087\n",
      "INFO:tensorflow:loss = 33.68083, step = 6401 (2.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.5534\n",
      "INFO:tensorflow:loss = 32.9371, step = 6501 (2.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.6505\n",
      "INFO:tensorflow:loss = 26.99783, step = 6601 (3.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.213\n",
      "INFO:tensorflow:loss = 28.867207, step = 6701 (2.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.132\n",
      "INFO:tensorflow:loss = 38.209995, step = 6801 (3.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.4933\n",
      "INFO:tensorflow:loss = 28.107233, step = 6901 (2.982 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 33.6962\n",
      "INFO:tensorflow:loss = 37.170376, step = 7001 (2.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.5468\n",
      "INFO:tensorflow:loss = 27.663883, step = 7101 (2.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.423\n",
      "INFO:tensorflow:loss = 36.25143, step = 7201 (2.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.7433\n",
      "INFO:tensorflow:loss = 25.212439, step = 7301 (2.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.3941\n",
      "INFO:tensorflow:loss = 24.141588, step = 7401 (2.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.0932\n",
      "INFO:tensorflow:loss = 30.983326, step = 7501 (2.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.7236\n",
      "INFO:tensorflow:loss = 23.889647, step = 7601 (2.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.899\n",
      "INFO:tensorflow:loss = 32.213017, step = 7701 (2.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.6878\n",
      "INFO:tensorflow:loss = 27.764402, step = 7801 (2.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.9327\n",
      "INFO:tensorflow:loss = 27.755241, step = 7901 (2.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.8781\n",
      "INFO:tensorflow:loss = 38.324306, step = 8001 (2.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.7917\n",
      "INFO:tensorflow:loss = 29.365133, step = 8101 (2.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.7839\n",
      "INFO:tensorflow:loss = 31.055798, step = 8201 (2.892 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.8824\n",
      "INFO:tensorflow:loss = 23.027103, step = 8301 (3.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.9536\n",
      "INFO:tensorflow:loss = 38.861923, step = 8401 (2.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.3707\n",
      "INFO:tensorflow:loss = 32.25578, step = 8501 (2.909 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.0327\n",
      "INFO:tensorflow:loss = 29.887085, step = 8601 (2.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.4885\n",
      "INFO:tensorflow:loss = 29.796787, step = 8701 (2.884 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.4681\n",
      "INFO:tensorflow:loss = 34.516865, step = 8801 (3.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.8532\n",
      "INFO:tensorflow:loss = 32.16877, step = 8901 (3.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.0945\n",
      "INFO:tensorflow:loss = 30.183775, step = 9001 (2.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.9399\n",
      "INFO:tensorflow:loss = 25.394758, step = 9101 (2.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.6968\n",
      "INFO:tensorflow:loss = 40.59235, step = 9201 (2.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.2401\n",
      "INFO:tensorflow:loss = 29.798101, step = 9301 (2.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.7768\n",
      "INFO:tensorflow:loss = 33.96483, step = 9401 (2.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.4587\n",
      "INFO:tensorflow:loss = 43.03131, step = 9501 (2.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.3379\n",
      "INFO:tensorflow:loss = 32.45837, step = 9601 (2.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.1048\n",
      "INFO:tensorflow:loss = 29.939573, step = 9701 (2.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.091\n",
      "INFO:tensorflow:loss = 38.629227, step = 9801 (2.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.7013\n",
      "INFO:tensorflow:loss = 25.843134, step = 9901 (2.866 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into C:\\Users\\Rahman\\AppData\\Local\\Temp\\tmpvfsfue7f\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 29.646961.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x257ab770208>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func,steps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "** Create a prediction input function with X_test data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fn = tf.estimator.inputs.pandas_input_fn(x=X_test,batch_size=len(X_test),shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use model.predict() and pass in input function. This will produce a generator of predictions, which we can then transform into a list **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Rahman\\AppData\\Local\\Temp\\tmpvfsfue7f\\model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = list(model.predict(input_fn=pred_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Each item in list will look like this: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': array([-5.5091677], dtype=float32),\n",
       " 'logistic': array([0.00403314], dtype=float32),\n",
       " 'probabilities': array([0.9959669 , 0.00403315], dtype=float32),\n",
       " 'class_ids': array([0], dtype=int64),\n",
       " 'classes': array([b'0'], dtype=object)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a list of only the class_ids key values from the prediction list of dictionaries, these are the predictions we will use to compare against the real y_test values. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred['class_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import classification_report from sklearn.metrics **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.93      0.91      7397\n",
      "          1       0.75      0.63      0.68      2372\n",
      "\n",
      "avg / total       0.85      0.86      0.85      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,final_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
